<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:site_name" content="BlogNews"><meta property="og:type" content="article"><meta name=robots content="index,follow,noarchive"><meta property="og:image" content="//img/home-bg-jeep.jpg"><meta property="twitter:image" content="//img/home-bg-jeep.jpg"><meta name=title content="SoC Tile, Part 2: Neural Processing Unit (NPU) Adds AI Inferencing on Chip"><meta property="og:title" content="SoC Tile, Part 2: Neural Processing Unit (NPU) Adds AI Inferencing on Chip"><meta property="twitter:title" content="SoC Tile, Part 2: Neural Processing Unit (NPU) Adds AI Inferencing on Chip"><meta name=description content="The last major block on the SoC tile is a full-featured Neural Processing Unit (NPU), a first for Intel's client-focused processors. The NPU brings AI capabilities directly to the chip and is compatible with standardized program interfaces like OpenVINO. The architecture of the NPU itself is multi-engine in nature, which is comprised of two neural"><meta property="og:description" content="The last major block on the SoC tile is a full-featured Neural Processing Unit (NPU), a first for Intel's client-focused processors. The NPU brings AI capabilities directly to the chip and is compatible with standardized program interfaces like OpenVINO. The architecture of the NPU itself is multi-engine in nature, which is comprised of two neural"><meta property="twitter:description" content="The last major block on the SoC tile is a full-featured Neural Processing Unit (NPU), a first for Intel's client-focused processors. The NPU brings AI capabilities directly to the chip and is compatible with standardized program interfaces like OpenVINO. The architecture of the NPU itself is multi-engine in nature, which is comprised of two neural"><meta property="twitter:card" content="summary"><meta name=keyword content><link rel="shortcut icon" href=./img/favicon.ico><title>SoC Tile, Part 2: Neural Processing Unit (NPU) Adds AI Inferencing on Chip |</title><link rel=canonical href=./intel-unveils-meteor-lake-architecture-intel-4-heralds-the-disaggregated-future-of-mobile-cpus.html><link rel=stylesheet href=https://assets.cdnweb.info/hugo/cleanwhite/css/bootstrap.min.css><link rel=stylesheet href=https://assets.cdnweb.info/hugo/cleanwhite/css/hugo-theme-cleanwhite.min.css><link rel=stylesheet href=https://assets.cdnweb.info/hugo/cleanwhite/css/zanshang.css><link href=https://cdn.jsdelivr.net/gh/FortAwesome/Font-Awesome@5.15.1/css/all.css rel=stylesheet type=text/css><script src=https://assets.cdnweb.info/hugo/cleanwhite/js/jquery.min.js></script>
<script src=https://assets.cdnweb.info/hugo/cleanwhite/js/bootstrap.min.js></script>
<script src=https://assets.cdnweb.info/hugo/cleanwhite/js/hux-blog.min.js></script></head><nav class="navbar navbar-default navbar-custom navbar-fixed-top"><div class=container-fluid><div class="navbar-header page-scroll"><button type=button class=navbar-toggle>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span></button>
<a class=navbar-brand href=./>BlogNews</a></div><div id=huxblog_navbar><div class=navbar-collapse><ul class="nav navbar-nav navbar-right"><li><a href=./categories/blog>blog</a></li><li><a href=./sitemap.xml>Sitemap</a></li><li><a href=./index.xml>RSS</a></li></ul></div></div></div></nav><script>var $body=document.body,$toggle=document.querySelector(".navbar-toggle"),$navbar=document.querySelector("#huxblog_navbar"),$collapse=document.querySelector(".navbar-collapse");$toggle.addEventListener("click",handleMagic);function handleMagic(){$navbar.className.indexOf("in")>0?($navbar.className=" ",setTimeout(function(){$navbar.className.indexOf("in")<0&&($collapse.style.height="0px")},400)):($collapse.style.height="auto",$navbar.className+=" in")}</script><style type=text/css>header.intro-header{background-image:url(/img/home-bg-jeep.jpg)}</style><header class=intro-header><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=post-heading><div class=tags></div><h1>SoC Tile, Part 2: Neural Processing Unit (NPU) Adds AI Inferencing on Chip</h1><h2 class=subheading></h2><span class=meta>Posted by
Reinaldo Massengill
on
Monday, March 25, 2024</span></div></div></div></div></header><article><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
post-container"><h2>SoC Tile, Part 2: NPU Adds a Physical AI Engine</h2><p>The last major block on the SoC tile is a full-featured Neural Processing Unit (NPU), a first for Intel's client-focused processors. The NPU brings AI capabilities directly to the chip and is compatible with standardized program interfaces like OpenVINO. The architecture of the NPU itself is multi-engine in nature, which is comprised of two neural compute engines that can either collaborate on a single task or operate independently. This flexibility is crucial for diverse workloads and potentially benefits future workloads that haven't yet been optimized for AI situations or are in the process of being developed. Two primary components of these neural compute engines stand out: the Inference Pipeline and the SHAVE DSP.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/20046/AI%20Deep%20Dive_FINAL%20CLEAN-32_575px.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>The Inference Pipeline is primarily responsible for executing workloads in neural network execution. It minimizes data movement and focuses on fixed-function operations for tasks that require high computational power. The pipeline comprises a sizable array of Multiply Accumulate (MAC) units, an activation function block, and a data conversion block. In essence, the inference pipeline is a dedicated block optimized for ultra-dense matrix math.</p><p>The SHAVE DSP, or Streaming Hybrid Architecture Vector Engine, is designed specifically for AI applications and workloads. It has the capability to be pipelined along with the Inference Pipeline and the Direct Memory Access (DMA) engine, thereby enabling parallel computing on the NPU to improve overall performance. The DMA Engine is designed to efficiently manage data movement, contributing to the system's overall performance.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/20046/AI%20Deep%20Dive_FINAL%20CLEAN-34_575px.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>At the heart of device management, the NPU is designed to be fully compatible with Microsoft's new compute driver model, known as MCDM. This isn't merely a feature, but it's an optimized implementation with a strong emphasis on security. The Memory Management Unit (MMU) complements this by offering multi-context isolation and facilitates rapid and power-efficient transitions between different power states and workloads.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/20046/AI%20Deep%20Dive_FINAL%20CLEAN-14_575px.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>As part of building an ecosystem that can capitalize on Intel's NPU, they have been embracing developers with a number of tools. One of these is the open-source <a href=#>OpenVINO toolkit</a>, which supports various models such as TensorFlow, PyTorch, and Caffe. Supported APIs include Windows Machine Learning (WinML), which also includes the DirectML component of the library, the ONNX Runtime accelerator, and OpenVINO.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/20046/AI%20Deep%20Dive_FINAL%20CLEAN-13_575px.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>One example of the capabilities of the NPU was provided through a demo using Audacity during Intel's Tech Tour in Penang, Malaysia. During this live demo, Intel Fellow Tom Peterson, used Audacity to showcase a new plugin called Riffusion. This fed a funky audio track with vocals through Audacity and separated the audio tracks into two, vocals and music. Using the Riffusion plugin to separate the tracks, Tom Peterson was then able to change the style of the music audio track to a dance track.</p><p>The Riffusion plugin for Audacity uses Stable Diffusion, which is an open-source AI model that traditionally generates images from text. Riffusion goes one step further by generating images of spectrograms, which can then be converted into audio. We touch on Riffusion and Stable Diffusion because this was Intel's primary showcase of the NPU during Intel's Tech Tour 2023 in Penang, Malaysia.&nbsp;</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/20046/AI%20Deep%20Dive_FINAL%20CLEAN-20_575px.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>Although it did require resources from both the compute and graphics tile, everything was brought together by the NPU, which processes multiple elements to spit out an EDM-flavored track featuring the same vocals. An example of how applications pool together the various tiles include those through WinML, which has been part of Microsoft's operating systems since Windows 10, typically runs workloads with the MLAS library through the CPU, while those going through DirectML are utilized by both the CPU and GPU.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/20046/AI%20Deep%20Dive_FINAL%20CLEAN-21_575px.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>Other developers include Microsoft, which uses the capability of the NPU in tandem with the OpenVINO inferencing engine to provide cool features like speech-to-text transcripts of meetings, audio improvements such as suppressing background noise, and even enhancing backgrounds and focusing capabilities. Another big gun using AI and is supported through the NPU is Adobe, which adds a host of features for adopters of Adobe Creative applications use. These features include generative AI capabilities, including photo manipulative techniques in Photoshop such as refining hair, editing elements, and neural filters; there's a lot going on.</p><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmivp6x7orrAp5utnZOde6S7zGiqoaenZH9xfJNvZqKmpJq5bsHNr5yipKNiuqbAxKipZqSRoLJurdGcn6KslZjBtr7EZqCnrJWhenV5x56pmqSUqHq1tMRmm6KrkZy0s7HGmquenF2bwrXB0Z5kqJ5doryjtcueZJyopah8dQ%3D%3D</p><hr><ul class=pager><li class=previous><a href=./what-happened-to-bubba-watson.html data-toggle=tooltip data-placement=top title="What Happened To Bubba Watson?">&larr;
Previous Post</a></li><li class=next><a href=./ryeo-un.html data-toggle=tooltip data-placement=top title="Ryeo Un- Net Worth, Age, Girlfriend, Dating, Ethnicity, Career">Next
Post &rarr;</a></li></ul></div><div class="col-lg-2 col-lg-offset-0
visible-lg-block
sidebar-container
catalog-container"><div class=side-catalog><hr class="hidden-sm hidden-xs"><h5><a class=catalog-toggle href=#>CATALOG</a></h5><ul class=catalog-body></ul></div></div><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
sidebar-container"><section><hr class="hidden-sm hidden-xs"><h5><a href=./tags/>FEATURED TAGS</a></h5><div class=tags></div></section></div></div></div></article><footer><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center"></ul><p class="copyright text-muted">Copyright &copy; BlogNews 2024<br><a href=https://themes.gohugo.io/hugo-theme-cleanwhite>CleanWhite Hugo Theme</a> |
<iframe style=margin-left:2px;margin-bottom:-5px frameborder=0 scrolling=0 width=100px height=20px src="https://ghbtns.com/github-btn.html?user=zhaohuabing&repo=hugo-theme-cleanwhite&type=star&count=true"></iframe></p></div></div></div></footer><script>function loadAsync(i,t){var n=document,s="script",e=n.createElement(s),o=n.getElementsByTagName(s)[0];e.src=i,t&&e.addEventListener("load",function(e){t(null,e)},!1),o.parentNode.insertBefore(e,o)}</script><script>$("#tag_cloud").length!==0&&loadAsync("/js/jquery.tagcloud.js",function(){$.fn.tagcloud.defaults={color:{start:"#bbbbee",end:"#0085a1"}},$("#tag_cloud a").tagcloud()})</script><script>loadAsync("https://cdn.jsdelivr.net/npm/fastclick@1.0.6/lib/fastclick.min.js",function(){var e=document.querySelector("nav");e&&FastClick.attach(e)})</script><script type=text/javascript>function generateCatalog(e){_containerSelector="div.post-container";var t,n,s,o,i,r=$(_containerSelector),a=r.find("h1,h2,h3,h4,h5,h6");return $(e).html(''),a.each(function(){n=$(this).prop("tagName").toLowerCase(),i="#"+$(this).prop("id"),s=$(this).text(),t=$('<a href="'+i+'" rel="nofollow">'+s+"</a>"),o=$('<li class="'+n+'_nav"></li>').append(t),$(e).append(o)}),!0}generateCatalog(".catalog-body"),$(".catalog-toggle").click(function(e){e.preventDefault(),$(".side-catalog").toggleClass("fold")}),loadAsync("https://assets.cdnweb.info/hugo/cleanwhite/js/jquery.nav.js",function(){$(".catalog-body").onePageNav({currentClass:"active",changeHash:!1,easing:"swing",filter:"",scrollSpeed:700,scrollOffset:0,scrollThreshold:.2,begin:null,end:null,scrollChange:null,padding:80})})</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/banner.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>